# Doctor Voice Assistant ğŸ©ºğŸ—£ï¸

An AI-powered medical assistant that listens to patient voice input, analyzes facial images using a multimodal LLM, and responds with a professional doctor's voice. Built using Python, Gradio, ElevenLabs, Groq, and gTTS.

---

## ğŸš€ Features

- ğŸ¤ **Speech-to-Text**: Converts patient's spoken input to text using Whisper (via Groq API)
- ğŸ§  **Image Diagnosis**: Analyzes uploaded images with a multimodal LLM (LLaMA via Groq) to simulate medical insight
- ğŸ—£ï¸ **Text-to-Speech**: Responds using AI-generated doctor's voice (via ElevenLabs or gTTS)
- ğŸŒ **Web Interface**: Clean and interactive Gradio-based UI for easy interaction

---

## ğŸ› ï¸ Tech Stack

- **Gradio** â€“ Web interface
- **Groq API** â€“ LLM and Whisper (for text/image understanding and transcription)
- **ElevenLabs** â€“ AI voice synthesis
- **gTTS** â€“ Fallback or alternative text-to-speech
- **SpeechRecognition & PyDub** â€“ Audio input and conversion
- **Python** â€“ Core logic and backend

---

## ğŸ–¼ï¸ Workflow Overview

1. **User speaks into mic**
2. **Audio transcribed to text**
3. **Image (if provided) is analyzed by the LLM**
4. **AI doctor replies with voice + text**

---

## ğŸ“ Project Structure

```bash
â”œâ”€â”€ voice_of_the_patient.py      # Records and transcribes voice input
â”œâ”€â”€ voice_of_the_doctor.py       # Converts text response to speech
â”œâ”€â”€ brain_of_the_doctor.py       # Image analysis with Groq's multimodal LLM
â”œâ”€â”€ gradio_app.py                # Gradio UI for interaction
â”œâ”€â”€ .env                         # API keys and secrets
â”œâ”€â”€ requirements.txt             # Python dependencies
